{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Welcome to our first Python Lab!**\n",
        "\n",
        "### We'll be using Python to build a simple machine learning model to talk about how AI models make decisions."
      ],
      "metadata": {
        "id": "dATjgDj4D1RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Setting Up the Dataset**\n",
        "\n",
        "We'll be using the [**Adult Income Dataset** from the UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/2/adult).\n",
        "\n",
        "This dataset examines whether a person earns more than $50K/year based on factors such as education, occupation, and marital status.\n",
        "\n",
        "It raises questions about fairness in predicting people’s income based on demographic characteristics, so it's a good example of the sociotechnical aspects of AI we discussed in lecture."
      ],
      "metadata": {
        "id": "G2Uvk1DsEOrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset from UCI (it’s available via many sources or from your own directory)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
        "                'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "                'hours_per_week', 'native_country', 'income']\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv(url, names=column_names, na_values=' ?')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "VcucpX69EJ3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "oChSpHvaq1ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "EpGg0l1_oCkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we dive into building a machine learning model, it's crucial to perform **exploratory data analysis (EDA)** to understand the dataset better. This will help us uncover trends, anomalies, and potential biases in the data. We'll look at descriptive statistics for numerical features, the distribution of categorical features, and visualize key attributes of the dataset."
      ],
      "metadata": {
        "id": "0q0nEJRXqyf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Get basic descriptive statistics\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "2ebTpIMnrBvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "SgiRF_KcoNA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now look at the distributions of important categorical features like race, sex, education, and workclass to check for imbalances."
      ],
      "metadata": {
        "id": "LqCP050XrLpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical feature distributions\n",
        "categorical_columns = ['relationship', 'native_country', 'race', 'sex', 'education', 'workclass', 'marital_status', 'occupation', 'income']\n",
        "\n",
        "# Displaying the distribution of each categorical variable\n",
        "for col in categorical_columns:\n",
        "    print(f\"\\nDistribution of {col}:\\n\")\n",
        "    print(df[col].value_counts(normalize=True) * 100)\n",
        "\n",
        "    # Plot each categorical variable in a separate chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(data=df, x=col, order=df[col].value_counts().index)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dqEh9PzmrRxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now explore the relationships between key features (like age, hours per week, and education_num) and the target variable (income) to see how they might influence the outcome."
      ],
      "metadata": {
        "id": "w15BD4wLsXJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting age, education_num, and hours_per_week vs income\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "sns.boxplot(data=df, x='income', y='age', ax=ax[0])\n",
        "ax[0].set_title('Age vs Income')\n",
        "\n",
        "sns.boxplot(data=df, x='income', y='education_num', ax=ax[1])\n",
        "ax[1].set_title('Education Level vs Income')\n",
        "\n",
        "sns.boxplot(data=df, x='income', y='hours_per_week', ax=ax[2])\n",
        "ax[2].set_title('Hours Worked per Week vs Income')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RJbb2hb9sXsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we’ll create a correlation heatmap to understand how the numerical features are correlated with one another. High correlations might indicate multicollinearity (where features are highly related), which we need to account for in modeling."
      ],
      "metadata": {
        "id": "gJxvnDIushbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Perform one-hot encoding for all categorical columns\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Check the column names to ensure 'income' is properly encoded\n",
        "print(df_encoded.columns)\n",
        "\n",
        "# Select only numeric columns for the correlation matrix\n",
        "numeric_df_encoded = df_encoded.select_dtypes(include=[np.number])\n",
        "\n",
        "# Display the correlation heatmap, including income\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(numeric_df_encoded.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Numerical and Encoded Categorical Features (Including Income)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IrtRTWFasggG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.dtypes"
      ],
      "metadata": {
        "id": "juP6RKh5a12L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to perform a train/test split to prepare for fitting the model."
      ],
      "metadata": {
        "id": "Dam-N7P_pXfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df_encoded.drop(columns=['income_ >50K'])  # Features (drop the encoded income column)\n",
        "y = df_encoded['income_ >50K']  # Target (income)\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Check the shape of the resulting datasets\n",
        "print(\"Training features shape:\", X_train.shape)\n",
        "print(\"Testing features shape:\", X_test.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Testing labels shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "k4_GfWKTpeqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Building a Simple Machine Learning Model**\n",
        "\n",
        "Now that the data is ready, let's build a Logistic Regression model to predict whether someone earns more than $50K/year."
      ],
      "metadata": {
        "id": "dbIXOVoRFws-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "tMx2ehZINuGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Evaluating the Model**\n",
        "\n",
        "After training, we need to evaluate the model to see how well it performs on the test data. We’ll use a **confusion matrix** to visualize the performance of the model.\n",
        "\n",
        "The confusion matrix helps us understand how many predictions were correct (true positives and true negatives) and how many were incorrect (false positives and false negatives).\n",
        "\n",
        "This breakdown is crucial for evaluating fairness and bias in the model."
      ],
      "metadata": {
        "id": "z1xjJ8Jfp329"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mp9s0cbinl97"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix and transpose it\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the confusion matrix with transposed axes\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* True Positives (TP): Correctly predicted high income.\n",
        "* True Negatives (TN): Correctly predicted low income.\n",
        "* False Positives (FP): Incorrectly predicted high income (overprediction).\n",
        "* False Negatives (FN): Incorrectly predicted low income (underprediction)."
      ],
      "metadata": {
        "id": "vO_cxCJcF97J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally speaking, the accuracy of a model is the ratio of correctly predicted instances to the total instances.\n",
        "\n",
        "Formula: (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "Let's calculate it using code:"
      ],
      "metadata": {
        "id": "XaPat5DPdFTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "7BizPkaCcyrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is the best-known general performance measure but it may not be reliable if there are class imbalances. In that case, it's better to break down the confusion matrix further for a more detailed analysis.\n",
        "\n",
        "One such measure is **precision**, or the proportion of positive identifications that were actually correct. It focuses on the **accuracy** of the **positive predictions**.\n",
        "\n",
        "It’s useful when the cost of false positives is high (e.g., in spam detection).\n",
        "\n",
        "Formula: TP / (TP + FP)"
      ],
      "metadata": {
        "id": "9dXaYLOydSVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(f\"Precision: {precision:.4f}\")"
      ],
      "metadata": {
        "id": "xZ1-RRJwc4uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next is recall, also known as sensitivity or true positive rate. It's the proportion of true positives out of all actual positives. It answers the question: Of all the actual positive instances, how many were correctly identified?\n",
        "\n",
        "It focuses on the model's ability to **capture all true positives**.\n",
        "\n",
        "Formula: TP / (TP + FN)"
      ],
      "metadata": {
        "id": "i6iffIQ4duWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Recall (Sensitivity or True Positive Rate)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "id": "-__KrOJyc9jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The F1 score is the harmonic mean of precision and recall. It balances the need for both precision and recall, and is useful when you want to avoid extremes of either metric.\n",
        "\n",
        "Formula: 2 * (Precision * Recall) / (Precision + Recall)"
      ],
      "metadata": {
        "id": "CWWopePReuYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1-Score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "pdAMfZCXc-wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC and AUC\n",
        "\n",
        "\n",
        "* The Receiver Operating Characteristic (ROC) curve plots the True Positive Rate (TPR; what we also referred to as recall or sensitivity earlier) against the False Positive Rate (FPR; the proportion of actual negatives incorrectly identified as positives) at various classification thresholds. It shows how well the model can distinguish between classes.\n",
        "\n",
        "\n",
        "* The Area Under the Curve (AUC) represents the area under the ROC curve. It’s a single scalar value that summarizes the ROC curve. A higher AUC indicates better model performance in distinguishing between classes."
      ],
      "metadata": {
        "id": "WAdHTeqQfTWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# Calculate the probability estimates for the test set\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "\n",
        "# Compute AUC\n",
        "auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (area = {auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Print AUC score\n",
        "print(f\"AUC: {auc:.2f}\")"
      ],
      "metadata": {
        "id": "5L6qVdopfSx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUC = 0.88 suggests that the model is not perfect but it's effective: it has a good ability to distinguish between the positive and negative classes.\n",
        "\n",
        "Some General AUC Ranges to use as a rule of thumb in analysis:\n",
        "* AUC = 1.0: Perfect model – the model makes no mistakes in classification.\n",
        "* AUC = 0.5: Random guessing – the model cannot distinguish between the classes (equivalent to flipping a coin).\n",
        "* AUC between 0.7 and 0.9: Good model – your model does a good job distinguishing between positive and negative cases.\n",
        "* AUC < 0.7: Poor model – the model struggles to separate the classes.\n"
      ],
      "metadata": {
        "id": "iyXTUJ2Nftkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Task:\n",
        "\n",
        "Although this dataset isn't classifying people into high-stakes categories like \"offender\" or \"non-offender,\" it is predicting whether someone earns more than $50k a year. From a responsible AI perspective, this can still be problematic. Explain how this type of prediction could negatively impact the individuals being classified by the algorithm, as well as the broader group of stakeholders who might not interact with the algorithm directly but could still be affected by its outcomes."
      ],
      "metadata": {
        "id": "Ako5_4FMlWZX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMXyVVrQl3wr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}